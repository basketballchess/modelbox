{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c4dae06",
   "metadata": {},
   "source": [
    "# Python SDK Tutorial\n",
    "This notebook explains how to use the Python SDK of Modelbox and explains the major concepts and how to use the API independent of any Deep Learning Framework. Please follow the PyTorch notebook to see how the SDK can be integrated with a PyTorch trainer. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631504a4",
   "metadata": {},
   "source": [
    "## Initialize the ModelBox Client\n",
    "First we initialize the client by pointing it to the address of the ModelBox Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c02d955",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelbox.modelbox import ModelBoxClient, MLFramework, Artifact, ArtifactMime, MetricValue\n",
    "\n",
    "client = ModelBoxClient(addr=\"localhost:8085\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03eb91b",
   "metadata": {},
   "source": [
    "## Create an Experiment \n",
    "Once we have a client, we can start using it to create a new Experiment to train a model or track an existing pre-trained model. Let us first see how to create an experiment. We are going to create an experiment to train a Wav2Vec Model with Pytorch and store it in a namespace called *langtech*. If you are using an experiment management service like Weights and Biases or Nepute, you could associate the ID from that service with modelbox to create a lineage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5a51e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e71a25a8d3d481463c281f083f5e2671ea2896bc'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = client.create_experiment(\"wav2vec\", \"owner@pytorch.org\", \"langtech\", \"extern123\", MLFramework.PYTORCH)\n",
    "experiment_id = resp.experiment_id\n",
    "experiment_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d810f5f",
   "metadata": {},
   "source": [
    "The above code is going to create a new experiment and give us an ID. You can list the experiments of a namespace by -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecf2d8e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Experiment(id='0672f152b8f413742167a4f73d441adfa6960b29', name='lid_quartznet-1154', owner='owner@pytorch.com', namespace='langtech', external_id='', created_at=seconds: 1659422641\n",
       " , updated_at=seconds: 1659422641\n",
       " ),\n",
       " Experiment(id='07d48614d4ffec028a73f0ef11734ac1115362bb', name='lid_quartznet-3822', owner='owner@pytorch.com', namespace='langtech', external_id='', created_at=seconds: 1659422167\n",
       " , updated_at=seconds: 1659422167\n",
       " ),\n",
       " Experiment(id='278a8d52955367ab3c308ccccecbaac1a62061fc', name='lid_quartznet-1586', owner='owner@pytorch.com', namespace='langtech', external_id='', created_at=seconds: 1659421558\n",
       " , updated_at=seconds: 1659421558\n",
       " ),\n",
       " Experiment(id='4016c95c530640352fe86ab04281eb11ff41d948', name='lid_quartznet-4651', owner='owner@pytorch.com', namespace='langtech', external_id='', created_at=seconds: 1659421456\n",
       " , updated_at=seconds: 1659421456\n",
       " ),\n",
       " Experiment(id='4186a686fcf5b18838c4f1e168603d1a12cef47a', name='lid_quartznet-8112', owner='owner@pytorch.com', namespace='langtech', external_id='', created_at=seconds: 1659422540\n",
       " , updated_at=seconds: 1659422540\n",
       " ),\n",
       " Experiment(id='42edf6ea8214e0d0616c766140775433468f1e48', name='lid_quartznet-3850', owner='owner@pytorch.com', namespace='langtech', external_id='', created_at=seconds: 1659421719\n",
       " , updated_at=seconds: 1659421719\n",
       " ),\n",
       " Experiment(id='4ceb8b4c7315a9157db003cdbdbb6a1d6527f65e', name='lid_quartznet-3031', owner='owner@pytorch.com', namespace='langtech', external_id='', created_at=seconds: 1659421416\n",
       " , updated_at=seconds: 1659421416\n",
       " ),\n",
       " Experiment(id='8691a5d7cc8b51a7474ba58ef546c52b1f99416f', name='lid_quartznet-5990', owner='owner@pytorch.com', namespace='langtech', external_id='', created_at=seconds: 1659422400\n",
       " , updated_at=seconds: 1659422400\n",
       " ),\n",
       " Experiment(id='997f4987e7dea05f9623d1bb0271be76aa798233', name='lid_quartznet-985', owner='owner@pytorch.com', namespace='langtech', external_id='', created_at=seconds: 1659422704\n",
       " , updated_at=seconds: 1659422704\n",
       " ),\n",
       " Experiment(id='9ac6c70bc94c839d3acb10cd5d811cee7a422691', name='lid_quartznet-2633', owner='owner@pytorch.com', namespace='langtech', external_id='', created_at=seconds: 1659421307\n",
       " , updated_at=seconds: 1659421307\n",
       " ),\n",
       " Experiment(id='a6b9566b80e926f6705d71452859cd339c12b092', name='lid_quartznet-3811', owner='owner@pytorch.com', namespace='langtech', external_id='', created_at=seconds: 1659422329\n",
       " , updated_at=seconds: 1659422329\n",
       " ),\n",
       " Experiment(id='b11d284b2b551d3513111dbb52a3d6b931122044', name='lid_quartznet-8079', owner='owner@pytorch.com', namespace='langtech', external_id='', created_at=seconds: 1659421693\n",
       " , updated_at=seconds: 1659421693\n",
       " ),\n",
       " Experiment(id='d397b88ba41baa17248637f31f1c512b5fd3a4dd', name='lid_quartznet-202', owner='owner@pytorch.com', namespace='langtech', external_id='', created_at=seconds: 1659423153\n",
       " , updated_at=seconds: 1659423153\n",
       " ),\n",
       " Experiment(id='e71a25a8d3d481463c281f083f5e2671ea2896bc', name='wav2vec', owner='owner@pytorch.org', namespace='langtech', external_id='', created_at=seconds: 1659593770\n",
       " , updated_at=seconds: 1659593770\n",
       " ),\n",
       " Experiment(id='fc5b0a49a66a58141a350fef06827bf845545b59', name='lid_quartznet-9729', owner='owner@pytorch.com', namespace='langtech', external_id='', created_at=seconds: 1659423764\n",
       " , updated_at=seconds: 1659423764\n",
       " )]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = client.list_experiments(namespace=\"langtech\")\n",
    "resp.experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8926dae8",
   "metadata": {},
   "source": [
    "#### Adding metadata\n",
    "Metadata can be added to any of the objects in ModelBox after they have been created. For example, once an experiment is created, metadata can be added and listed at any stage -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8025ffb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ListMetadataResponse(metadata={'foo/bar': 12.0})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_resp = client.update_metadata(experiment_id, \"foo/bar\", 12)\n",
    "resp = client.list_metadata(experiment_id)\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774a768d",
   "metadata": {},
   "source": [
    "## Working with Checkpoints\n",
    "Once we have an experiment we can create model checkpoints from the trainers. Lets assume the file stored in assets/mnist_checkpoint1.pt is a checkpoint created by the trainer. We will now associate this checkpoint with ModelBox.\n",
    "\n",
    "We could either track the path of the checkpoint or upload the blob and let ModelBox store it in the configured blob store. The benefit of letting modelbox store the blob is that the trainer doesn't need to have access to the blob store directly. However, in some cases it's more optimal to have the trainer store the blob directly, when the path to IO to the blob store from the trainer is much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb6323ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'97f7fccf8d2d67aa78d7d58a86b5d938ddff9f38'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "checkpoint_path = os.path.abspath('mnist_cnn_checkpoint1.pt')\n",
    "metrics = {'val_accu': 98.5, 'train_accu': 99.2}\n",
    "resp = client.create_checkpoint(experiment=experiment_id, epoch=1, path=checkpoint_path, metrics=metrics)\n",
    "checkpoint_id = resp.checkpoint_id\n",
    "checkpoint_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489ea146",
   "metadata": {},
   "source": [
    "This returns us the checkpoint ID and tracks the path of the checkpoint created by the trainer.\n",
    "\n",
    "Now let's say that we also want ModelBox to store the checkpoint, we will simply set the flag `upload` in the above api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a2ab84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resp = client.create_checkpoint(experiment_id, 2, checkpoint_path, metrics, upload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783bd85b",
   "metadata": {},
   "source": [
    "Once checkpoints are created they can be listed by passing the experiment name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4daee87e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ListCheckpointsResponse(checkpoints=[Checkpoint(id='97f7fccf8d2d67aa78d7d58a86b5d938ddff9f38', experiment_id='e71a25a8d3d481463c281f083f5e2671ea2896bc', epoch=1)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.list_checkpoints(experiment_id=experiment_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c690dee",
   "metadata": {},
   "source": [
    "## Working with Models and ModelVersions\n",
    "\n",
    "Model objects describe tasks performed, metadata, which datasets are used to train, how to use the models during inference, etc. ModelVersions are trained instances of a model. So for example over time an English ASR(speech to text) model can have multiple model versions as they are trained with different datasets and such. \n",
    "\n",
    "We don't prescribe the granularity of Models and ModelVersions. If it's easier to create different Models every time a new model is trained with different hyperparameters and a single ModelVersion pointing to the model artifacts and all the metrics that is fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e9bbc1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'93b7cf0bec10ff6d500a9273bc34ab7eff02eeca'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = client.create_model(name='asr_en', owner='owner@owner.org', namespace='langtech', task='asr', description='ASR for english', metadata={'x': 'y'})\n",
    "model_id = resp.id\n",
    "model_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4760fe7",
   "metadata": {},
   "source": [
    "In the same way a ModelVersion can be created by the client, and track the associated artifacts and metadata.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a48f0d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0ae662556996e18f364a41b82cd1a4e043062687'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags =[\"test\"]\n",
    "resp = client.create_model_version(model_id=model_id, name=\"asr_en_july\", version=\"1\", description='ASR for english', metadata={'x': 'y'}, unique_tags=tags, files=[], framework=MLFramework.PYTORCH.to_proto())\n",
    "model_version_id = resp.id\n",
    "model_version_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fe5d37",
   "metadata": {},
   "source": [
    "Once a modelversion is created we can upload the model and associate with the model version object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99487ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UploadFileResponse(id='5a0094ee34e88d826a84ef831444b152b9c2c91a')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = '/home/diptanuc/Projects/modelbox/tutorials/artifacts/mnist_cnn.pt'\n",
    "resp = client.upload_file(parent='0ae662556996e18f364a41b82cd1a4e043062687', path=model_path)\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912b53a2",
   "metadata": {},
   "source": [
    "The model file can now be served by the file server built into Model Box to inference servers. Inference services can either use the language specific SDKs in Python, Rust or Go or call the GRPC `DownloadFile` API directly which streams the files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293fe5be",
   "metadata": {},
   "source": [
    "> **_NOTE: Checkpoints Transforms to ModelVersions_** \n",
    "Usually in production engineers look at checkpoints/models created during training and select a version which has the best metrics. Once we have the worker infrastructure in place, we will create APIs which to do automatic convertion of checkpoints to ModelVersions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d145152f",
   "metadata": {},
   "source": [
    "## Tracking Artifacts and Working with Files\n",
    "Modelbox can track artifacts used in training and also users can upload Files and associate them with experiments, models and model versions. For example, a user can track the dataset files used for training stored in S3 or even upload them to ModelBox. A trained model can be uploaded and then later streamed to applications for inferencing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a325e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrackArtifactsResponse(num_artifacts_tracked=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "file_path = str(\n",
    "            pathlib.Path(\".\").parent.resolve().joinpath(\"artifacts/test_artifact.txt\")\n",
    "        )\n",
    "artifacts = [Artifact(parent='93b7cf0bec10ff6d500a9273bc34ab7eff02eeca', mime_type=ArtifactMime.Text, path=file_path)]\n",
    "resp = client.track_artifacts(artifacts=artifacts)\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c029e37d",
   "metadata": {},
   "source": [
    "Modelbox is now tracking the artifact and has information about the checksum, local path of the file, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4629da68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Artifact(parent='93b7cf0bec10ff6d500a9273bc34ab7eff02eeca', path='/home/diptanuc/Projects/modelbox/tutorials/artifacts/test_artifact.txt', mime_type=<ArtifactMime.Unknown: 0>, checksum='0019d23bef56a136a1891211d7007f6f', id='')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = client.list_models(namespace='langtech')\n",
    "artifacts = result.models[0].artifacts\n",
    "artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc63ee7",
   "metadata": {},
   "source": [
    "## Metrics \n",
    "ModelBox supports adding Metrics to experiments. Metrics can be logged to a key with values being a float, string or bytes. Metric values are associated with a step unit, and wallclock time when the metric was emitted by the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c67a930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Metrics(key='val_accu', values=[[MetricValue(step=1, wallclock_time=1659595326, value=0.7300000190734863), MetricValue(step=1, wallclock_time=1659595419, value=0.7300000190734863), MetricValue(step=1, wallclock_time=1659595449, value=0.7300000190734863), MetricValue(step=2, wallclock_time=1659595449, value=0.7799999713897705)]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "client.log_metrics(parent_id=experiment_id, key=\"val_accu\", value=MetricValue(step=1, wallclock_time=int(time.time()), value=0.73))\n",
    "client.log_metrics(parent_id=experiment_id, key=\"val_accu\", value=MetricValue(step=2, wallclock_time=int(time.time()), value=0.78))\n",
    "\n",
    "client.get_metrics(experiment_id)['val_accu']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7da99f9",
   "metadata": {},
   "source": [
    "Metrics can be added to any of the modelbox objects including Model, ModelVersion."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
